{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mplsoccer import Sbopen\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import streamlit as st\n",
    "from joblib import load\n",
    "from db_connection import get_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "statsbomb_api = Sbopen()\n",
    "db = next(get_db())\n",
    "competition_list = statsbomb_api.competition()\n",
    "competitions = competition_list[~competition_list['match_available_360'].isna()]\n",
    "\n",
    "matches = []\n",
    "for _, competition in competitions.iterrows():\n",
    "    if  True or competition.season_id == 282:\n",
    "        df_match = statsbomb_api.match(competition_id=competition['competition_id'] , season_id=competition['season_id'])\n",
    "        new = df_match.match_id.unique()\n",
    "        matches.extend(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "425"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "except\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x000002703EECA450>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\juras\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 790, in _clean_thread_parent_frames\n",
      "    active_threads = {thread.ident for thread in threading.enumerate()}\n",
      "                                                 ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juras\\miniconda3\\envs\\football-scouting\\Lib\\threading.py\", line 1535, in enumerate\n",
      "    def enumerate():\n",
      "    \n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "from matplotlib import widgets\n",
    "\n",
    "event_df = pd.DataFrame()\n",
    "track_df = pd.DataFrame()\n",
    "\n",
    "progress = widgets.IntProgress(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=len(set(matches)),\n",
    "    description='Loading:',\n",
    "    bar_style='',\n",
    "    style={'bar_color': 'blue'},\n",
    "    orientation='horizontal'\n",
    ")\n",
    "display(progress)\n",
    "    \n",
    "for match in matches:\n",
    "    try:\n",
    "        df = statsbomb_api.event(match)\n",
    "        df2 = statsbomb_api.frame(match)\n",
    "        df_event = df[0]\n",
    "        df_track = df2[0]\n",
    "        event_df = pd.concat([event_df, df_event], ignore_index=True)\n",
    "        track_df = pd.concat([track_df, df_track], ignore_index=True)\n",
    "        event_df.reset_index(drop=True, inplace=True)\n",
    "        track_df.reset_index(drop=True, inplace=True)\n",
    "        progress.value +=1\n",
    "    except:\n",
    "        print('except')\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df = event_df.dropna(subset=['x', 'y'])\n",
    "event_df = event_df[~event_df[['x', 'y']].isin([float('inf'), float('-inf')]).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df[event_df[['end_x', 'end_y']].isna().any(axis=1)].type_name.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if no end => start == end\n",
    "event_df.loc[event_df['end_x'].isna(), 'end_x'] = event_df['x']\n",
    "event_df.loc[event_df['end_y'].isna(), 'end_y'] = event_df['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Pitch Zones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(event_df['x'].min(),event_df['x'].max())\n",
    "print(event_df['y'].min(),event_df['y'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pitch_zone(x, y):\n",
    "    # Define horizontal zones (x-axis)\n",
    "    if x < 40:\n",
    "        horiz_zone = 'Defensive'\n",
    "    elif x <= 80:\n",
    "        horiz_zone = 'Middle'\n",
    "    else:\n",
    "        horiz_zone = 'Attacking'\n",
    "\n",
    "    # Define vertical zones (y-axis)\n",
    "    if y < 20:\n",
    "        vert_zone = 'Right'\n",
    "    elif y <= 60:\n",
    "        vert_zone = 'Center'\n",
    "    else:\n",
    "        vert_zone = 'Left'\n",
    "    \n",
    "    return f\"{horiz_zone} {vert_zone}\"\n",
    "\n",
    "# Apply function to create start and end zones\n",
    "event_df['start_zone'] = event_df.apply(lambda row: get_pitch_zone(row['x'], row['y']), axis=1)\n",
    "event_df['end_zone'] = event_df.apply(lambda row: get_pitch_zone(row['end_x'], row['end_y']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_event = event_df\n",
    "\n",
    "df_event[\"position_name\"].unique()\n",
    "\n",
    "position_map = {\n",
    "\n",
    "    \"Center Forward\": \"Striker\",\n",
    "    \"Left Center Forward\": \"Striker\",\n",
    "    \"Right Center Forward\": \"Striker\",\n",
    "    \"Second Striker\": \"Striker\",\n",
    "    \"Striker\": \"Striker\",\n",
    "\n",
    "    # --- Center Backs ---\n",
    "    \"Center Back\": \"Center Back\",\n",
    "    \"Left Center Back\": \"Center Back\",\n",
    "    \"Right Center Back\": \"Center Back\",\n",
    "\n",
    "    # --- Fullbacks & Wingbacks ---\n",
    "    \"Left Back\": \"Wide Back\",\n",
    "    \"Right Back\": \"Wide Back\",\n",
    "    \"Left Wing Back\": \"Wide Back\",\n",
    "    \"Right Wing Back\": \"Wide Back\",\n",
    "\n",
    "    # --- Central Midfielders ---\n",
    "    \"Center Midfield\": \"Center Midfield\",\n",
    "    \"Left Center Midfield\": \"Center Midfield\",\n",
    "    \"Right Center Midfield\": \"Center Midfield\",\n",
    "    \"Center Defensive Midfield\": \"Center Midfield\",\n",
    "    \"Left Defensive Midfield\": \"Center Midfield\",\n",
    "    \"Right Defensive Midfield\": \"Center Midfield\",\n",
    "    \"Center Attacking Midfield\": \"Center Midfield\",\n",
    "    \"Left Attacking Midfield\": \"Center Midfield\",\n",
    "    \"Right Attacking Midfield\": \"Center Midfield\",\n",
    "\n",
    "    # --- Wide Midfielders / Wingers ---\n",
    "    \"Left Midfield\": \"Wide Midfield\",\n",
    "    \"Right Midfield\": \"Wide Midfield\",\n",
    "    \"Left Wing\": \"Wide Midfield\",\n",
    "    \"Right Wing\": \"Wide Midfield\",\n",
    "\n",
    "    \"Goalkeeper\": \"Goalkeeper\",\n",
    "}\n",
    "\n",
    "df_event[\"pos_group\"] = df_event[\"position_name\"].map(position_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Compute Movement Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_event['distance'] = np.sqrt((df_event['x'] - df_event['end_x']) ** 2 + (df_event['y'] - df_event['end_y']) ** 2)\n",
    "df_event['progression'] = df_event['end_x'] - df_event['x']\n",
    "df_event['directness'] = np.where(df_event['distance'] != 0, df_event['progression'] / df_event['distance'], 0)\n",
    "df_event['width_change'] = abs(df_event['end_y'] - df_event['y'])\n",
    "#df_event['speed'] = np.where(df_event['duration'] != 0, df_event['distance'] / df_event['duration'], 0)\n",
    "#df_event['distance_covered'] = np.sqrt((df_event['end_x'] - df_event['x']) ** 2 + (df_event['end_y'] - df_event['y']) ** 2)\n",
    "#df_event['angle_change'] = np.arctan2(df_event['end_y'] - df_event['y'], df_event['end_x'] - df_event['x'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Packing Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_pos = event_df.loc[:,['id', 'x', 'y', 'end_x', 'end_y']]\n",
    "id_pos = id_pos.rename(columns={'x': 'ball_x', 'y': 'ball_y'})\n",
    "track_df_full = track_df.merge(id_pos, on='id', how='left')\n",
    "track_df_full = track_df_full[track_df_full['actor']==False]\n",
    "track_df_full['distance'] = np.sqrt((track_df_full['x'] - track_df_full['ball_x'])**2 + (track_df_full['y'] - track_df_full['ball_y'])**2)\n",
    "\n",
    "# ball went behind the opponent\n",
    "track_df_full['packing'] = (track_df_full['x'] > track_df_full['ball_x']) & (track_df_full['x'] < track_df_full['end_x'])\n",
    "\n",
    "\n",
    "teammates_df = track_df_full[track_df_full['teammate'] == True]\n",
    "teammates_df = teammates_df.rename(columns={'distance': 'teammate_distance'})\n",
    "\n",
    "teammates_df['teammate_behind_ball'] = (teammates_df['ball_x'] > teammates_df['ball_x'])\n",
    "\n",
    "opponents_df = track_df_full[track_df_full['teammate'] == False]\n",
    "opponents_df = opponents_df.rename(columns={'distance': 'opponent_distance'})\n",
    "\n",
    "track_df_full['nearby_opponents'] = (track_df_full['distance'] < 10) & (track_df_full['teammate']==False)\n",
    "track_df_full['nearby_teammates'] = (track_df_full['distance'] < 10) & (track_df_full['teammate']==True)\n",
    "\n",
    "\n",
    "teammate_distance_min = teammates_df.groupby(['id'])['teammate_distance'].min().reset_index()\n",
    "opponent_distance_min = opponents_df.groupby('id')['opponent_distance'].min().reset_index()\n",
    "\n",
    "\n",
    "\n",
    "distance_count = track_df_full.groupby('id')['nearby_opponents'].sum().reset_index()\n",
    "distance_count_teammates = track_df_full.groupby('id')['nearby_teammates'].sum().reset_index()\n",
    "packing = opponents_df.groupby('id')['packing'].sum().reset_index()\n",
    "teammate_forward = teammates_df.groupby('id')['teammate_behind_ball'].sum().reset_index()\n",
    "\n",
    "\n",
    "df_event = df_event.merge(distance_count, on='id', how='left')\n",
    "df_event = df_event.merge(distance_count_teammates, on='id', how='left')\n",
    "df_event = df_event.merge(teammate_distance_min, on='id', how='left')\n",
    "df_event = df_event.merge(opponent_distance_min, on='id', how='left')\n",
    "df_event = df_event.merge(packing, on='id', how='left')\n",
    "df_event = df_event.merge(teammate_forward, on='id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Player level aggregation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\", \".join(df_event.columns.to_list()))\n",
    "df_event['sub_type_name'].unique()\n",
    "df_event['body_part_name'].unique()\n",
    "df_event[df_event['type_name'] == \"Dribble\"]['outcome_name'].unique()\n",
    "#df_event[df_event['type_name'] == \"Shot\"]['shot_first_time'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pressure = df_event.groupby(['player_id'])['under_pressure'].sum().reset_index()\n",
    "df_pressure.rename(columns={'under_pressure': 'pressure_count'}, inplace=True)\n",
    "\n",
    "# Count event types \n",
    "df_counts = df_event.groupby(['player_id'])['type_name'].value_counts().unstack(fill_value=0).reset_index()\n",
    "df_counts = df_counts[['player_id', 'Pass', 'Carry', 'Dribble', 'Shot', 'Duel', 'Pressure', 'Block', 'Ball Recovery', 'Interception', 'Clearance', 'Foul Won', 'Foul Committed']].fillna(0)\n",
    "\n",
    "df_position_groups = df_event.groupby(['player_id'])['pos_group'].value_counts(normalize=True).unstack(fill_value=0).reset_index()\n",
    "\n",
    "\n",
    "# Passes\n",
    "\n",
    "df_pass = df_event[(df_event['type_name'] == 'Pass')].groupby(['player_id']).agg(\n",
    "    all_passes = ('pass_length', 'count'),\n",
    "    successful_passes = ('outcome_name', lambda x: (x.isin([np.nan, 'Complete', 'Success', 'Success In Play', 'Success To Team'])).sum()),\n",
    "    avg_pass_length = ('pass_length', 'mean'),\n",
    "    avg_pass_angle = ('pass_angle', 'mean'),\n",
    "    longest_forward_pass = ('progression', 'max'),\n",
    "    pass_switch = ('pass_switch', 'count'),\n",
    "    pass_cut_back = ('pass_cut_back', 'count')\n",
    ").reset_index()\n",
    "df_pass['pass_success_rate'] = df_pass['successful_passes'] / df_pass['all_passes']\n",
    "df_pass.fillna(0, inplace=True)\n",
    "\n",
    "df_pass_types = df_event[df_event['type_name'] == 'Pass'].groupby(['player_id'])['pass_height_name'].value_counts(normalize=True).unstack(fill_value=0).reset_index()\n",
    "df_pass_types.columns = ['player_id'] + [f'{col.lower().replace(\" \", \"_\")}' for col in df_pass_types.columns[1:]]\n",
    "\n",
    "# Shots\n",
    "\n",
    "df_shot = df_event[(df_event['type_name'] == 'Shot')].groupby(['player_id']).agg(\n",
    "    all_shots = ('id', 'count'),\n",
    "    shot_mean_length = ('x', 'mean'),\n",
    "    headers = ('body_part_name', lambda x: (x.isin(['Head'])).sum()),\n",
    "    extra_shots = ('technique_name', lambda x: (~x.isin(['Normal'])).sum()),\n",
    "    first_time_shots = ('shot_first_time', 'count'),\n",
    "    total_xg = ('shot_statsbomb_xg', 'sum')\n",
    ")\n",
    "df_shot.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# Dribbles\n",
    "df_event['forward'] = df_event[\"x\"] - df_event[\"end_x\"]\n",
    "df_event['vertical'] = abs(df_event[\"y\"] - df_event[\"end_y\"])\n",
    "\n",
    "df_dribble = df_event[(df_event['type_name'] == 'Dribble')].groupby(['player_id']).agg(\n",
    "    successful_dribbles = ('outcome_name', lambda x: (x.isin(['Complete'])).sum()),\n",
    "    dribble_length_forward = ('forward', 'mean'),\n",
    "    dribble_length_vertical =  ('vertical', 'mean'),\n",
    "    dribble_start_x = ('x', 'mean')\n",
    ")\n",
    "df_dribble.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# Aggregate movement features\n",
    "df_movement = df_event.groupby(['player_id']).agg(\n",
    "    total_distance=('distance', 'sum'),\n",
    "    avg_progression=('progression', 'mean'),\n",
    "    avg_directness=('directness', 'mean'),\n",
    "    total_width_change=('width_change', 'sum'),\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "\n",
    "# Aggregate pitch zone counts (start zones)\n",
    "df_pitch_zones = df_event.groupby(['player_id'])['start_zone'].value_counts(normalize=True).unstack(fill_value=0).reset_index()\n",
    "df_pitch_zones.columns = ['player_id'] + [f'start_{col.lower().replace(\" \", \"_\")}' for col in df_pitch_zones.columns[1:]]\n",
    "\n",
    "# Aggregate pitch zone counts (end zones)\n",
    "df_pitch_zones_end = df_event.groupby(['player_id'])['end_zone'].value_counts(normalize=True).unstack(fill_value=0).reset_index()\n",
    "df_pitch_zones_end.columns = ['player_id'] + [f'end_{col.lower().replace(\" \", \"_\")}' for col in df_pitch_zones_end.columns[1:]]\n",
    "\n",
    "\n",
    "# Pressure & support\n",
    "df_pressure_support = df_event.groupby(['player_id']).agg(\n",
    "    avg_opponent_distance = ('opponent_distance', 'mean'),\n",
    "    avg_teammate_distance = ('teammate_distance', 'mean'),\n",
    "    avg_opponent_count = ('nearby_opponents', 'mean'),\n",
    "    avg_teammate_count = ('nearby_teammates', 'mean'),\n",
    "    avg_advanced_players = ('teammate_behind_ball', 'mean')\n",
    "    ).reset_index()\n",
    "\n",
    "# Packing\n",
    "df_packing = df_event.groupby(['player_id']).agg(\n",
    "    total_packing=('packing', 'sum')).reset_index()\n",
    "\n",
    "\n",
    "df_counterpress = df_event.groupby(['player_id'])['counterpress'].sum().reset_index()\n",
    "df_counterpress.rename(columns={'counterpress': 'counterpress_count'}, inplace=True)\n",
    "\n",
    "\n",
    "df_aerial_duels = df_event.groupby(['player_id'])['aerial_won'].sum().reset_index()\n",
    "df_aerial_duels.rename(columns={'aerial_won': 'aerial_duels_won'}, inplace=True)\n",
    "\n",
    "df_duration = df_event.groupby(['player_id']).agg(avg_duration=('duration', 'mean')).reset_index()\n",
    "\n",
    "\n",
    "# Merge all aggregated data into a possession-level DataFrame\n",
    "player_features = df_counts \\\n",
    "    .merge(df_pass, on=['player_id'], how='left') \\\n",
    "    .merge(df_shot, on=['player_id'], how='left') \\\n",
    "    .merge(df_dribble, on=['player_id'], how='left') \\\n",
    "    .merge(df_pressure, on=['player_id'], how='left') \\\n",
    "    .merge(df_movement, on=['player_id'], how='left') \\\n",
    "    .merge(df_pass_types, on=['player_id'], how='left') \\\n",
    "    .merge(df_position_groups, on=['player_id'], how='left') \\\n",
    "    .merge(df_pitch_zones, on=['player_id'], how='left') \\\n",
    "    .merge(df_pitch_zones_end, on=['player_id'], how='left') \\\n",
    "    .merge(df_counterpress[['player_id', 'counterpress_count']], on=['player_id'], how='left') \\\n",
    "    .merge(df_aerial_duels[['player_id', 'aerial_duels_won']], on=['player_id'], how='left') \\\n",
    "    .merge(df_duration[['player_id', 'avg_duration']], on=['player_id'], how='left') \\\n",
    "    .merge(df_pressure_support, on=['player_id'], how='left') \\\n",
    "    .merge(df_packing, on=['player_id'], how='left')\n",
    "\n",
    "# Fill NaN values with 0 where needed\n",
    "player_features.fillna(0, inplace=True)\n",
    "possession_features_original = player_features.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_convert = [ 'pass_switch', 'pass_cut_back', 'aerial_duels_won']\n",
    "\n",
    "for col in columns_to_convert:\n",
    "    player_features[col] = player_features[col].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sql_schemas import PlayingTimes, Competitions\n",
    "from db_connection import get_db\n",
    "from sqlalchemy import text\n",
    "\n",
    "db = next(get_db())\n",
    "playing_times = db.query(PlayingTimes).all()\n",
    "db.close()\n",
    "df = pd.DataFrame([vars(r) for r in playing_times]).drop(columns=\"_sa_instance_state\")\n",
    "df\n",
    "total_minutes_df = df.groupby([\"player_id\", \"player_name\"])[\"minutes\"].sum().reset_index()\n",
    "total_minutes_df\n",
    "player_features = player_features.merge(total_minutes_df, on=['player_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_features.to_excel('../../excel/player_features.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_features = pd.read_excel('../../excel/player_features.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Wide Focus = Width-related features (Summing all start & end width-related positions)\n",
    "player_features[\"wide_focus\"] = (\n",
    "    player_features[\"start_attacking_left\"] +\n",
    "    player_features[\"start_attacking_right\"] +\n",
    "    player_features[\"start_middle_left\"] +\n",
    "    player_features[\"start_middle_right\"] +\n",
    "    player_features[\"start_defensive_left\"] +\n",
    "    player_features[\"start_defensive_right\"] +\n",
    "    player_features[\"end_attacking_left\"] +\n",
    "    player_features[\"end_attacking_right\"] +\n",
    "    player_features[\"end_middle_left\"] +\n",
    "    player_features[\"end_middle_right\"] +\n",
    "    player_features[\"end_defensive_left\"] +\n",
    "    player_features[\"end_defensive_right\"]\n",
    ")\n",
    "\n",
    "player_features[\"defensive_start\"] = (\n",
    "    player_features[\"start_defensive_left\"] +\n",
    "    player_features[\"start_defensive_right\"] +\n",
    "    player_features[\"start_defensive_center\"]\n",
    ")\n",
    "player_features[\"middle_start\"] = (\n",
    "    player_features[\"start_middle_left\"] +\n",
    "    player_features[\"start_middle_right\"] +\n",
    "    player_features[\"start_middle_center\"]\n",
    ")\n",
    "player_features[\"attacking_start\"] = (\n",
    "    player_features[\"start_attacking_left\"] +\n",
    "    player_features[\"start_attacking_right\"] +\n",
    "    player_features[\"start_attacking_center\"]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "per90_columns = ['Pass', 'Carry', 'Dribble', 'Shot', 'Duel', 'Pressure',\n",
    "       'Block', 'Ball Recovery', 'Interception', 'Clearance', 'Foul Won',\n",
    "       'Foul Committed', 'pass_switch', 'pass_cut_back', 'mean_length',\n",
    "       'headers', 'extra_shots', 'total_xg',\n",
    "       'successful_dribbles', 'pressure_count',\n",
    "       'total_distance', 'total_width_change', 'counterpress_count',\n",
    "       'aerial_duels_won', 'total_packing', 'wide_focus']\n",
    "player_features[per90_columns] = player_features[per90_columns].div(player_features[\"minutes\"], axis=0) * 90\n",
    "player_features.to_excel('../../excel/player_features_p90.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dropping original columns to avoid redundancy\n",
    "features_to_drop = [\n",
    "    # Wide Focus Components\n",
    "    \"start_attacking_left\", \"start_attacking_right\", \"start_middle_left\", \"start_middle_right\", \"start_defensive_left\", \"start_defensive_right\",\n",
    "    \"start_attacking_center\", \"start_defensive_center\", \"start_middle_center\",\n",
    "    \"end_attacking_left\", \"end_attacking_right\", \"end_middle_left\", \"end_middle_right\", \"end_defensive_left\", \"end_defensive_right\",\n",
    "    \"end_attacking_center\", \"end_defensive_center\", \"end_middle_center\",\n",
    "\n",
    "\n",
    "    'all_passes', 'successful_passes','all_shots',\n",
    "    # Highly Correlated Features\n",
    "    #\"ground_pass\",\"total_width_change\", \"successful_passes\", \"pressure_count\",\"all_passes\", \"total_distance\",\n",
    "    #\"total_width_change\", \"total_packing\", \"total_duration\", \"wide_focus\", \"defensive_intensity\", \"on_ball_actions\", \"defensive_actions\"\n",
    "    # 'avg_directness','low_pass', 'Shot',\n",
    "    #   'pass_switch', 'pass_cut_back', 'aerial_duels_won', 'defensive_start', 'middle_start'\n",
    "]\n",
    "player_features_dr = player_features.drop(columns=features_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_features_dr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "non_numeric_cols = ['player_id', 'player_name', 'minutes']\n",
    "\n",
    "df_numeric = player_features_dr.drop(columns=non_numeric_cols, errors='ignore')\n",
    "corr_matrix = df_numeric.corr()\n",
    "plt.figure(figsize=(16, 12))\n",
    "sns.heatmap(corr_matrix, annot=False, cmap=\"coolwarm\", center=0, linewidths=0.5, vmin=-1, vmax=1)\n",
    "plt.title(\"Feature Correlation Heatmap\", fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "corr_matrix = df_numeric.corr().abs()\n",
    "upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "high_corr_pairs = [\n",
    "    (col, row, upper_triangle.loc[row, col])\n",
    "    for col in upper_triangle.columns\n",
    "    for row in upper_triangle.index\n",
    "    if upper_triangle.loc[row, col] > 0.80\n",
    "]\n",
    "\n",
    "if high_corr_pairs:\n",
    "    print(\"Highly correlated feature pairs (correlation > 0.80):\")\n",
    "    for col1, col2, corr_value in high_corr_pairs:\n",
    "        print(f\"{col1} and {col2}: {corr_value:.2f}\")\n",
    "else:\n",
    "    print(\"No feature pairs with correlation greater than 0.80.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric.columns  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1️⃣ Standardize the data\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(df_numeric)\n",
    "\n",
    "# 2️⃣ Apply PCA\n",
    "pca = PCA()\n",
    "pca.fit(scaled_features)\n",
    "\n",
    "# 3️⃣ Plot Explained Variance\n",
    "explained_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(explained_variance) + 1), explained_variance, marker='o', linestyle='--')\n",
    "plt.axhline(y=0.90, color='r', linestyle='--', label='90% Variance Threshold')\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('PCA - Explained Variance')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 4️⃣ Determine the Optimal Number of Components\n",
    "n_components = np.argmax(explained_variance >= 0.90) + 1  # Selecting components explaining ≥90% variance\n",
    "print(f\"Optimal number of components: {n_components}\")\n",
    "\n",
    "# 5️⃣ Transform Data Using PCA\n",
    "pca_final = PCA(n_components=n_components)\n",
    "pca_features = pca_final.fit_transform(scaled_features)\n",
    "\n",
    "# 6️⃣ Create DataFrame with PCA components\n",
    "pca_df = pd.DataFrame(pca_features, columns=[f'PC{i+1}' for i in range(n_components)])\n",
    "\n",
    "# 7️⃣ Analyze Feature Loadings (Contribution of each feature to principal components)\n",
    "loadings = pd.DataFrame(pca_final.components_.T, index=df_numeric.columns, columns=[f'PC{i+1}' for i in range(n_components)])\n",
    "print(\"PCA Feature Loadings:\")\n",
    "print(loadings)\n",
    "\n",
    "# 8️⃣ Visualize the first two principal components\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=pca_df['PC1'], y=pca_df['PC2'], alpha=0.6)\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('PCA Projection (PC1 vs PC2)')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1️⃣ Determine the optimal number of clusters using the Elbow Method\n",
    "wcss = []  # Within-cluster sum of squares\n",
    "\n",
    "max_cluster_test = 50\n",
    "\n",
    "for i in range(2, max_cluster_test):  # Testing between 2 and 10 clusters\n",
    "    kmeans = KMeans(n_clusters=i, random_state=42)\n",
    "    kmeans.fit(pca_df)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "# Plotting the Elbow Curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(2, max_cluster_test), wcss, marker='o', linestyle='--')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# 2️⃣ Silhouette Score to support the elbow method\n",
    "silhouette_scores = []\n",
    "for n_clusters in range(2, max_cluster_test):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(pca_df)\n",
    "    silhouette_avg = silhouette_score(pca_df, cluster_labels)\n",
    "    silhouette_scores.append(silhouette_avg)\n",
    "\n",
    "# Plot Silhouette Scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(2, max_cluster_test), silhouette_scores, marker='s', linestyle='-', color='orange')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Score for Optimal Clusters')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# 3️⃣ Apply K-Means with the optimal number of clusters (let's assume 4 based on elbow/silhouette)\n",
    "optimal_clusters = 23  # Adjust this based on your elbow/silhouette plot results\n",
    "kmeans_final = KMeans(n_clusters=optimal_clusters, random_state=42)\n",
    "\n",
    "# Predict clusters\n",
    "pca_df['Cluster'] = kmeans_final.fit_predict(pca_df)\n",
    "\n",
    "\n",
    "# 5️⃣ Analyze the average feature values per cluster (to profile playing styles)\n",
    "cluster_profiles = pd.concat([pca_df, df_numeric.reset_index(drop=True)], axis=1)\n",
    "cluster_summary = cluster_profiles.groupby('Cluster').mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_features[\"Cluster\"] = pca_df['Cluster']\n",
    "player_features.columns\n",
    "names_unique = event_df.loc[:,['player_id']].drop_duplicates(subset=[\"player_id\"]).reset_index()\n",
    "player_features_with_name = player_features.merge(names_unique, on=\"player_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_features_with_name[player_features_with_name[\"Cluster\"]==21].loc[:,[\"Goalkeeper\", \"Center Back\", \"Wide Back\", \"Center Midfield\", \"Wide Midfield\", \"Striker\", \"player_name\", \"minutes\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = player_features_with_name.loc[:,[\"Cluster\", 'avg_pass_length', 'wide_focus', 'attacking_start','total_xg']].groupby([\"Cluster\"]).describe().T\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_summary.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_features['Cluster'] = pca_df['Cluster']\n",
    "df_event_with_clusters = df_event.merge(\n",
    "    player_features[['player_id', 'Cluster']],\n",
    "    on=['player_id'],\n",
    "    how='left')\n",
    "df_event_with_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2️⃣ Calculate Cluster Distribution per Team\n",
    "team_playing_styles = df_event_with_clusters.groupby(['player_id']).size().unstack(fill_value=0)\n",
    "\n",
    "\n",
    "# Normalize to get percentages\n",
    "team_playing_styles_percentage = team_playing_styles.div(team_playing_styles.sum(axis=1), axis=0) * 100\n",
    "\n",
    "team_playing_styles_percentage\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 3️⃣ Stacked Bar Plot for Team Playing Styles\n",
    "plt.figure(figsize=(12, 8))\n",
    "team_playing_styles_percentage.plot(kind='bar', stacked=True, figsize=(14, 8), colormap='Set2')\n",
    "\n",
    "plt.title('Team Playing Style Distribution')\n",
    "plt.xlabel('Team')\n",
    "plt.ylabel('Percentage of Possessions')\n",
    "plt.legend(title='Playing Style Cluster', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(team_playing_styles_percentage, annot=True, fmt='.1f', cmap='YlGnBu', linewidths=0.5)\n",
    "\n",
    "plt.ylabel('Team')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.xticks(rotation=20)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1️⃣ Mapping Cluster Numbers to Style Names\n",
    "cluster_to_style = {\n",
    "    0: 'High long ball from defense',\n",
    "    1: 'Build-up against high press',\n",
    "    2: 'Set pieces or crosses close to goal',\n",
    "    3: 'Regular attack transition',\n",
    "    4: 'Long possession during build-up'\n",
    "}\n",
    "\n",
    "# Apply the mapping\n",
    "team_playing_styles_percentage.rename(columns=cluster_to_style, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 2️⃣ Radar Plot Function\n",
    "def plot_team_playing_style_radar(team_name, data):\n",
    "    styles = data.columns.tolist()\n",
    "    values = data.loc[team_name].values.tolist()\n",
    "\n",
    "    # Close the radar plot\n",
    "    values += values[:1]\n",
    "    angles = np.linspace(0, 2 * np.pi, len(styles), endpoint=False).tolist()\n",
    "    angles += angles[:1]\n",
    "\n",
    "    # Plotting\n",
    "    fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
    "    ax.plot(angles, values, linewidth=2, linestyle='solid', label=team_name)\n",
    "    ax.fill(angles, values, alpha=0.25)\n",
    "\n",
    "    # Setting labels\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(styles, fontsize=10)\n",
    "    ax.set_yticklabels([])  # Remove radial ticks for clarity\n",
    "\n",
    "    plt.title(f'Playing Style Radar for {team_name}', size=14, y=1.1)\n",
    "    plt.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n",
    "    plt.show()\n",
    "\n",
    "# Example: Plotting for a specific team\n",
    "plot_team_playing_style_radar('Croatia', team_playing_styles_percentage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_team_playing_style_radar('Spain', team_playing_styles_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import Session\n",
    "from sql_schemas import Possessions\n",
    "\n",
    "\n",
    "def init_possessions(db: Session, df, tableClass = Possessions):\n",
    "    db.query(tableClass).delete()\n",
    "    db.commit()\n",
    "    new_rows = [\n",
    "        tableClass(\n",
    "            match_id=p['match_id'], possession=p['possession'], \n",
    "            playing_style=cluster_to_style.get(p['playing_style']),\n",
    "            passes=p['Pass'],\n",
    "            carry=p['Carry'],\n",
    "            dribble=p['Dribble'],\n",
    "            shot=p['Shot'],\n",
    "            duel=p['Duel'],\n",
    "            pressure=p['Pressure'],\n",
    "            block=p['Block'],\n",
    "            ball_recovery=p['Ball Recovery'],\n",
    "            interception=p['Interception'],\n",
    "            clearance=p['Clearance'],\n",
    "            avg_pass_length=p['avg_pass_length'],\n",
    "            pass_success_rate=p['pass_success_rate'],\n",
    "            possession_team_name=p['possession_team_name']\n",
    "        )\n",
    "        for p in df.to_dict(orient=\"records\")\n",
    "    ]\n",
    "    print(new_rows)\n",
    "    if new_rows:\n",
    "        db.bulk_save_objects(new_rows)\n",
    "    db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possession_features_original['Cluster'] = player_features['Cluster']\n",
    "possession_features_original.to_csv('test.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assume you already have X and cluster labels\n",
    "X = pd.read_csv('test.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = possession_features_original\n",
    "df['playing_style'] = df['Cluster']\n",
    "possession_team = event_df.groupby(['match_id', 'possession'])['possession_team_name'].max().reset_index()\n",
    "possession_team\n",
    "df = df.merge(possession_team[['match_id', 'possession', 'possession_team_name']], on=['match_id', 'possession'], how='left')\n",
    "df\n",
    "#df_final = df.rename(columns={\"Pass\": \"passes\"})\n",
    "#df_final\n",
    "\n",
    "init_possessions(db,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "team_possessions = df.groupby(['possession_team_name', 'Cluster']).size().unstack(fill_value=0)\n",
    "\n",
    "\n",
    "# Normalize to get percentages\n",
    "team_possessions_percentage = team_possessions.div(team_possessions.sum(axis=1), axis=0) * 100\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.heatmap(team_possessions_percentage, annot=True, fmt='.1f', cmap='YlGnBu', linewidths=0.5)\n",
    "\n",
    "plt.title('Heatmap of Team Playing Styles (%)')\n",
    "plt.xlabel('Playing Style Cluster')\n",
    "plt.ylabel('Team')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_team_playing_style_radar('Spain', team_possessions_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster\n",
    "df_numeric['Cluster'] = df['Cluster']\n",
    "labels = df['Cluster']\n",
    "\n",
    "for cluster_id in np.unique(labels):\n",
    "    cluster_points = scaled_features[labels == cluster_id]\n",
    "    for row in cluster_points:\n",
    "        plt.plot(row, alpha=0.2, color=f'C{cluster_id}')\n",
    "    plt.plot(cluster_points.mean(axis=0), color=f'C{cluster_id}', label=f'Cluster {cluster_id}', linewidth=2)\n",
    "\n",
    "plt.xlabel(\"Feature Index\")\n",
    "plt.ylabel(\"Feature Value\")\n",
    "plt.title(\"Feature-wise Profile of Each Cluster\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_numeric.loc[:,['start_x', 'end_x', 'total_xg', 'longest_forward_pass', 'Cluster']], hue='Cluster', corner=True, diag_kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = kmeans_final.cluster_centers_\n",
    "print(centers.shape) \n",
    "centers_original_space = pca_final.inverse_transform(centers)\n",
    "cluster_centers_orig = scaler.inverse_transform(centers_original_space)\n",
    "\n",
    "columns = [col for col in df_numeric.columns if col != 'Cluster']\n",
    "df_centers = pd.DataFrame(cluster_centers_orig, columns=columns)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(df_centers.T, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Clusters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "cluster_summary_cleaned = cluster_summary.loc[:, ~cluster_summary.columns.str.startswith('PC')]\n",
    "plt.figure(figsize=(12, 8))  # adjust size as needed\n",
    "sns.heatmap(cluster_summary_cleaned.T, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Clusters\")\n",
    "plt.show()\n",
    "cluster_summary.T.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "print(scaled_features)\n",
    "cluster_profiles = pd.DataFrame(scaled_features, columns=df_numeric.columns[:-1], index=df_numeric.index)\n",
    "cluster_profiles['Cluster'] = df_numeric['Cluster']\n",
    "cluster_summary = cluster_profiles.groupby('Cluster').mean()\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(cluster_summary.T, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Clusters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_event_with_clusters.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_event_with_clusters.loc[:,['type_name','player_name','position_name','Cluster']]\n",
    "df_event_with_clusters = df_event_with_clusters[df_event_with_clusters['position_name'].str.contains(\"Forward\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df_event_with_clusters.groupby(['player_name', 'Cluster'])['type_name'].value_counts().reset_index()\n",
    "\n",
    "b = df_event_with_clusters[df_event_with_clusters['type_name'] == 'Pass'].groupby(['player_name', 'Cluster'])['outcome_name'].apply(lambda g: g.isna().mean()).reset_index()\n",
    "a[a['Cluster'] == 4].sort_values(by='count', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.merge(b, on=['player_name', 'Cluster'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = a[a['type_name'] == 'Dribble'][a['count']> 3]\n",
    "c.sort_values(by='outcome_name', ascending=False).head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "football-scouting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
